{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77b0fa0e",
   "metadata": {
    "id": "77b0fa0e",
    "papermill": {
     "duration": 0.029071,
     "end_time": "2022-07-26T08:40:37.426805",
     "exception": false,
     "start_time": "2022-07-26T08:40:37.397734",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CS328 Assignment 3: Human Activity Recognition Using Machine Learning\n",
    "\n",
    "The objective of this assignment is to develop your understanding and practical application skills in the field of machine learning, particularly focusing on Human Activity Recognition (HAR). Human Activity Recognition has become increasingly important in various fields including health care, personal fitness, smart homes, and surveillance. In this assignment, you will be working with a dataset collected from a wrist-worn device, which includes accelerometer data. The data has been classified into nine distinct activities: downstairs, jogging, lying, sitting, standing, upstairs, walking fast, walking moderate, and walking slow.\n",
    "\n",
    "You will get hands-on experience in several key aspects of machine learning and data processing:\n",
    "1. Data collection and preprocessing from multiple sources for analysis\n",
    "2. Understand how to create windows of raw data through resampling and to extract meaningful features from these windows.\n",
    "3. Hands-on experience on how to extract features, encode target variables, split datasets, train models, make predictions, and evaluate the performance of these models.\n",
    "4. Learn to assess your trained modelâ€™s performance using common metrics like accuracy, confusion matrix and more. Understanding how well your models are performing is crucial in any machine learning task.\n",
    "\n",
    "Through this assignment, you will be able to develop a pipeline for Human Activity Recognition that can be further fine-tuned for different tasks or datasets. You will be able to apply the skills and knowledge gained here to other machine learning projects and real-world applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1fe6a0",
   "metadata": {
    "id": "fd1fe6a0"
   },
   "source": [
    "#### Imports Block\n",
    "\n",
    "Make sure all imports are in this block below (and leave the two comments IMPORTS START and IMPORT END as is. The extractor script uses the START and END delimitors when extracting the functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "53536412",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-26T08:40:37.481354Z",
     "iopub.status.busy": "2022-07-26T08:40:37.480505Z",
     "iopub.status.idle": "2022-07-26T08:40:40.877204Z",
     "shell.execute_reply": "2022-07-26T08:40:40.875881Z"
    },
    "id": "53536412",
    "papermill": {
     "duration": 3.427823,
     "end_time": "2022-07-26T08:40:40.880880",
     "exception": false,
     "start_time": "2022-07-26T08:40:37.453057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -- IMPORTS START --\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from scipy.signal import butter, filtfilt, find_peaks\n",
    "from sklearn.tree import DecisionTreeClassifier,export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "# -- IMPORTS END --\n",
    "\n",
    "# enable zooming into graphs\n",
    "%matplotlib notebook\n",
    "plt.rcParams['figure.figsize'] = [9, 6] # width, height in inches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176444cb",
   "metadata": {
    "id": "176444cb"
   },
   "source": [
    "### Helper Function: viz_tree (do not modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4ffb5eaa",
   "metadata": {
    "id": "4ffb5eaa"
   },
   "outputs": [],
   "source": [
    "# Helper function to visualize model - Do not modify\n",
    "def viz_tree(dt_model,features_frames,cnames):\n",
    "    # Fix feature names as list\n",
    "    feature_names = features_frames.columns.tolist()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9,4))\n",
    "    tree.plot_tree(dt_model,\n",
    "                   feature_names=feature_names,\n",
    "                   fontsize=7,\n",
    "                   class_names=cnames,\n",
    "                   filled=True,\n",
    "                   ax=ax)\n",
    "\n",
    "    plt.title('Decision Tree')\n",
    "    plt.savefig('dt.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc0fd91",
   "metadata": {
    "id": "2bc0fd91"
   },
   "source": [
    "### Helper Function: calc_magnitude (same as prev assignment - do not modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "26629e32",
   "metadata": {
    "id": "26629e32"
   },
   "outputs": [],
   "source": [
    "#Do not modify\n",
    "def calc_magnitude(data):\n",
    "\n",
    "    # Calculate magnitude\n",
    "    data['accel_mag'] = np.sqrt(data['x']**2 + data['y']**2 + data['z']**2) # absolute accel magnitude\n",
    "    data['accel_mag'] = data['accel_mag'] - data['accel_mag'].mean() # detrend: \"remove gravity\"\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c396d9",
   "metadata": {
    "id": "15c396d9"
   },
   "source": [
    "### Helper Function: remove noise (same as prev assignment - do not modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c69e662e",
   "metadata": {
    "id": "c69e662e"
   },
   "outputs": [],
   "source": [
    "#Do not modify\n",
    "def remove_noise(data,sampling_rate):\n",
    "    from scipy.signal import butter, filtfilt, find_peaks\n",
    "\n",
    "    # Low pass filter\n",
    "    cutoff = 5 # Hz\n",
    "    order = 2\n",
    "    b, a = butter(order, cutoff/(sampling_rate/2), btype='lowpass')\n",
    "    data['filtered_accel_mag'] = filtfilt(b, a, data['accel_mag'])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fc1443",
   "metadata": {
    "id": "37fc1443"
   },
   "source": [
    "### Helper Function: add_features (from prev assignment; do not modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "eaa7fca9",
   "metadata": {
    "id": "eaa7fca9"
   },
   "outputs": [],
   "source": [
    "#Do not modify\n",
    "def add_features(window):\n",
    "    features = {}\n",
    "    features['avg'] = window['filtered_accel_mag'].mean()\n",
    "    features['max'] = window['filtered_accel_mag'].quantile(1)\n",
    "    features['med'] = window['filtered_accel_mag'].quantile(0.5)\n",
    "    features['min'] = window['filtered_accel_mag'].quantile(0)\n",
    "    features['q25'] = window['filtered_accel_mag'].quantile(0.25)\n",
    "    features['q75'] = window['filtered_accel_mag'].quantile(0.75)\n",
    "    features['std'] = window['filtered_accel_mag'].std()\n",
    "    df = pd.DataFrame()\n",
    "    df = df._append(features,ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2679dc62",
   "metadata": {
    "id": "2679dc62"
   },
   "source": [
    "### Helper Function: train_decision_tree (from prev assignment; do not modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "66551f04",
   "metadata": {
    "id": "66551f04"
   },
   "outputs": [],
   "source": [
    "def train_decision_tree(frames):\n",
    "    # Extract feature columns\n",
    "    X = frames[['avg', 'max', 'med', 'min', 'q25', 'q75', 'std']]\n",
    "\n",
    "    # Extract target column\n",
    "    y = frames['activity']\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Create model\n",
    "    dt_model = DecisionTreeClassifier(criterion='entropy',max_depth=5).fit(X_train, y_train)\n",
    "    dt_pred = dt_model.predict(X_test)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    acc = dt_model.score(X_test, y_test)\n",
    "    dt_cm = confusion_matrix(y_test, dt_pred, labels=dt_model.classes_)\n",
    "    print(classification_report(y_test, dt_pred))\n",
    "    print(\"Accuracy on test set:\", acc)\n",
    "\n",
    "    return dt_model,dt_cm,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455bd83a",
   "metadata": {
    "id": "455bd83a"
   },
   "source": [
    "### Assignment Function 1: extract_features(data, window_sec, sample_rate,activity)\n",
    "\n",
    "**Instructions:**\n",
    "Define the `extract_features` function that extracts features from accelerometer data by applying a sliding window approach. \n",
    "\n",
    "**This is almost the same as extract_features from Assignment 2 except that you are given the `activity` label as input**\n",
    "\n",
    "**Hints and Instructions:**\n",
    "Use the `pandas.DataFrame.resample` function to implement the sliding window approach. Remember to use the computed features when appending to the new DataFrame.\n",
    "\n",
    "- The function takes as arguments:\n",
    "  - `data`: a DataFrame containing the filtered acceleration magnitude signal and annotated step locations\n",
    "  - `window_sec`: the window length in seconds for feature extraction\n",
    "  - `sample_rate`: the sampling frequency of the accelerometer data\n",
    "  - `activity`: the activity label for each window you extract\n",
    "- The function will perform the following:\n",
    "  - For each window in the resampled data:\n",
    "    - Call the `add_features` function to compute features of the window\n",
    "  - Append the computed features to a new DataFrame and return this DataFrame\n",
    "\n",
    "**Rubrics:**\n",
    "\n",
    "Function 1 : 15%\n",
    "1. Correctly called add_features and adds the features to the DataFrame (60%)\n",
    "2. Adds the activity label to the dataframe (20%)\n",
    "3. Appends and returns the correct DataFrame (20%)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a54fb629",
   "metadata": {
    "id": "a54fb629"
   },
   "outputs": [],
   "source": [
    "# Function to extract windows and features\n",
    "def extract_features(data, window_sec, sample_rate, activity):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04a2a41",
   "metadata": {
    "id": "c04a2a41"
   },
   "source": [
    "### Assignment Function 2: all_data_to_combined_csv(data, window_sec, sample_rate,activity)\n",
    "\n",
    "This function is expected to process data collected from different activities, extract features and store everything into a combined CSV file.\n",
    "\n",
    "**Hint and Instructions:**\n",
    "Understand how the `glob`, `pandas` and `os` modules work. Understand how the `calc_magnitude` and `remove_noise` function work. Use `os.path.basename(filename)` to extract the activity\n",
    "\n",
    "- Write a function named `all_data_to_combined_csv(root, output_filename)`.\n",
    "- This function will process the data collected from various activities such as downstairs, jogging, lying, sitting, standing, upstairs, walking fast, moderate and slow. These activities' data are stored in different .csv files within their respective folders.\n",
    "- the `root` will be the root folder of all the files.\n",
    "- the `output_filename` will be the filename of the combined csv file. The file is located at `folder/output_filename`.\n",
    "- Use the glob module to create a list of all .csv files from each activity's directory.\n",
    "- The pandas DataFrame `all_data` is initialized to store the processed data from all activities.\n",
    "- The function will then loop over each activity's data file. For each file:\n",
    "    - read each .csv file into a pandas DataFrame.\n",
    "    - From the raw data, calculate the magnitude and remove any noise.\n",
    "    - Extract the activity type for each file.\n",
    "    - extract features using the `extract_features()` function.\n",
    "    - append the feature frames into the all_data dataframe.\n",
    "- Continue this process until all .csv files from all activities have been processed.\n",
    "- Finally, the function writes the `all_data` DataFrame to a new .csv file named 'all_data.csv'.\n",
    "\n",
    "**Rubrics:** \n",
    "\n",
    "Function 2: 15%\n",
    "1. Correctly looped over all the files and read each csv (40%)\n",
    "2. Preprocess the data and adds the activity column (40%)\n",
    "3. Appends and returns the correct DataFrame (20%)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cc737c7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-26T08:40:40.937663Z",
     "iopub.status.busy": "2022-07-26T08:40:40.937222Z",
     "iopub.status.idle": "2022-07-26T08:40:41.155127Z",
     "shell.execute_reply": "2022-07-26T08:40:41.153548Z"
    },
    "id": "cc737c7e",
    "papermill": {
     "duration": 0.251452,
     "end_time": "2022-07-26T08:40:41.158659",
     "exception": false,
     "start_time": "2022-07-26T08:40:40.907207",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def all_data_to_combined_csv(root, output_filename = 'all_data.csv'):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce2f24b",
   "metadata": {},
   "source": [
    "## Assignment: Collect your own data\n",
    "\n",
    "In this section, we will collect your own data of different activities.\n",
    "\n",
    "For each team member in the team, please collect one minute data for each activities including `downstairs`, `jogging`, `lying`, `sitting`, `standing`, `upstairs`, `walk_fast`, `walk_mod` and `walk_slow`.  \n",
    "\n",
    "Follow the similar folder structures as `data/Activities`, store the csv files in the folder under `MyData/*`. \n",
    "\n",
    "The data should look like:\n",
    "- data\n",
    "    - Activities\n",
    "    - MyData\n",
    "        - downstairs\n",
    "        - jogging\n",
    "        - lying\n",
    "        - sitting\n",
    "        - standing\n",
    "        - upstairs\n",
    "        - walk_fast\n",
    "        - walk_mod\n",
    "        - walk_slow\n",
    "\n",
    "Due to the fact that sensor logger data has a UTC ticks time instead of datetime, we should transform the time first. Feel free to modify the below function so that all the collected data has the same datetime format as the provided data.\n",
    "\n",
    "**Rubrics:**\n",
    "Function 3: 20%\n",
    "1. Collect your own data (100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e32b8d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_time_to_datetime(root):\n",
    "    \n",
    "    dateparse = lambda dates: [pd.to_datetime(d, unit='ns') for d in dates]\n",
    "    # Get list of all activity folders\n",
    "    activity_folders = os.listdir(root)\n",
    "    # print(activity_folders)\n",
    "\n",
    "    for folder in activity_folders:\n",
    "        # print(folder)\n",
    "        files = glob.glob(f\"{root}/{folder}/*.csv\")\n",
    "        for filename in files:\n",
    "            # print(filename)\n",
    "            df = pd.read_csv(filename, parse_dates=['time'])\n",
    "            df['time'] = pd.to_datetime(pd.to_numeric(df['time']), unit='ns')\n",
    "            df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bc437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_time_to_datetime('./data/MyData')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0773023f",
   "metadata": {
    "id": "0773023f"
   },
   "source": [
    "## Assignment: Testing Classifier Performance\n",
    "\n",
    "In this section, we will evaluate the overall performance of our activity classifier using a combined dataset of all activities. This process helps understand how accurately the model can classify a wide variety of activities. The steps are as follows:\n",
    "\n",
    "1. **Data Generation**: We start by calling the `all_data_to_combined_csv()` function. This function processes all the individual activity datasets, applies the necessary preprocessing, and generates a combined CSV file named 'all_data.csv'. Note that the function only creates this file once, so if you need to recreate it with updated preprocessing or feature extraction, you should delete the existing file first.\n",
    "\n",
    "2. **Data Loading**: Once we have the combined CSV file, we load it into a pandas DataFrame for further use.\n",
    "\n",
    "3. **Activity Selection**: Next, we choose a subset of activities to exclude from the dataset. We do this by listing them in the `drop_activities` array. The remaining activities will be the ones our decision tree model tries to classify. You can experiment with different subsets of activities to see how it impacts the model's accuracy.\n",
    "\n",
    "4. **Model Training**: The `train_decision_tree` function is then called with the chosen classes. This function trains the decision tree model and evaluates its performance, printing the precision, recall, and accuracy metrics. It also returns the trained model, the confusion matrix, and the overall accuracy for further use.\n",
    "\n",
    "5. **Performance Visualization**: To provide a visual understanding of the model's performance, we display the confusion matrix using matplotlib's `ConfusionMatrixDisplay` function. Each row of the matrix corresponds to a true class, while each column corresponds to a predicted class. The diagonal elements represent correctly classified instances, and off-diagonal elements are instances that are misclassified.\n",
    "\n",
    "6. **Decision Tree Visualization**: Finally, we visualize the decision tree using the `viz_tree` function. This function generates a graphic representation of the decision tree model, showing how it makes decisions based on the features.\n",
    "\n",
    "This section's output can help understand how well the model generalizes to different activities and how different features influence the model's decisions. Remember that it's normal if the model performs better on some activities than others, depending on the complexity and distinctiveness of the activities.\n",
    "\n",
    "We provided an example of how to evaluate the model on your own data, feel free to modify it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "637b27fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dt_model, filtered_collected_data):\n",
    "    X_test = filtered_collected_data[['avg', 'max', 'med', 'min', 'q25', 'q75', 'std']]\n",
    "\n",
    "    # Extract target column\n",
    "    y_test = filtered_collected_data['activity']\n",
    "\n",
    "    dt_pred = dt_model.predict(X_test)\n",
    "    # Evaluate on test set\n",
    "    acc = dt_model.score(X_test, y_test)\n",
    "    # dt_cm = confusion_matrix(y_test, dt_pred, labels=dt_model.classes_)\n",
    "    print(classification_report(y_test, dt_pred))\n",
    "    print(\"Accuracy on test set:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c05debc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the data under data/Activities\n",
    "all_data_to_combined_csv(root='./data/Activities')\n",
    "\n",
    "# Combine all the data collected from team members\n",
    "all_data_to_combined_csv(root='./data/MyData')\n",
    "\n",
    "feature_frames = pd.read_csv('./data/Activities/all_data.csv')\n",
    "collected_frames = pd.read_csv('./data/MyData/all_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa40e93",
   "metadata": {
    "id": "eaa40e93"
   },
   "source": [
    "# Part 2: Experimenting with Different Activity Combinations\n",
    "\n",
    "In this task, we want you to experiment with different combinations of activities and observe the impact on the decision tree model's accuracy. Understanding how varying the activities impacts the model's performance can provide valuable insight into the distinctiveness of the movements and their complexity.\n",
    "\n",
    "1. **Three Types of Walking**: To do this, modify the `activities` list to only include 'walk_fast', 'walk_mod', and 'walk_slow'. Run the training code and note the accuracy.\n",
    "\n",
    "2. **Stairs Activities**: Next, modify the `activities` list to only include 'upstairs' and 'downstairs'. Run the training code and note the accuracy.\n",
    "\n",
    "3. **Static Activities**: For this run, modify the `activities` list to only include 'lying', 'sitting', and 'standing'. Run the training code and note the accuracy.\n",
    "\n",
    "4. **Mobile Activities**: Now, consider all the activities involving movement i.e. exclude 'lying', 'sitting', and 'standing' in the `activities` list. Run the training code and note the accuracy.\n",
    "\n",
    "5. **All Activities**: Finally, all activities are included in the training process. Run the training code and note the accuracy.\n",
    "\n",
    "For each experiment, set the depth of the decision tree to 5.\n",
    "\n",
    "### What To Report\n",
    "For each of the above combinations,\n",
    "- **Fill up** this table based on the results you obtain by trying different parameters (only modify the first line). We will evaluate the accuracy of numbers you fill up below.\n",
    "- **Interpretation of the results**: What do these accuracy scores suggest about the ability of the model to distinguish between these activities? Do some activities appear to be more distinguishable than others? How do different combinations of activities affect the accuracy? Remember to provide a brief discussion for each point.\n",
    "\n",
    "\n",
    "**Rubrics:**\n",
    "Part 2:\n",
    "Function 3: 50% - Each combination - 10%\n",
    "1. Accuracy, precision, recall Table Filled up\n",
    "2. Accuracy, precision, recall for your collected data Fill up\n",
    "3. Interpretation of the results\n",
    "4. Compare the obtained results in terms of precision, recall, and accuracy, and provide your interpretation of these results. For example, if your precision is lower than accuracy, why do you think that is the case? Or if your recall is higher than precision, what might that indicate based on your experience, and so on.\n",
    "\n",
    "Hint: You can use the confusion_matrix to get precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c2bf39",
   "metadata": {
    "id": "a0c2bf39",
    "outputId": "43c12d34-4f9f-46ad-e8d0-8fe8bf85fe27",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "activities = ['walk_fast','walk_mod','walk_slow']\n",
    "\n",
    "# Invert mask to keep only other rows\n",
    "filtered_feature_frames = feature_frames[feature_frames['activity'].isin(activities)]\n",
    "filtered_collected_frames = collected_frames[feature_frames['activity'].isin(activities)]\n",
    "\n",
    "# Train the decision tree with the chosen classes\n",
    "# This function will print out precision/recall/accuracy\n",
    "dt_model, dt_cm, acc = train_decision_tree(filtered_feature_frames)\n",
    "\n",
    "# Save the classifier to disk. The name should be exactly dt_model.pkl\n",
    "with open(f'dt_model-{str(activities)}.pkl', 'wb') as f:\n",
    "    pickle.dump(dt_model, f)\n",
    "\n",
    "# Display the confusion matrix\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = dt_cm, display_labels=dt_model.classes_)\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "\n",
    "# Visualize the tree\n",
    "viz_tree(dt_model,feature_frames,feature_frames['activity'].unique().tolist())\n",
    "\n",
    "evaluate(dt_model, filtered_collected_frames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13710cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = ['upstairs','downstairs']\n",
    "\n",
    "# Invert mask to keep only other rows\n",
    "filtered_feature_frames = feature_frames[feature_frames['activity'].isin(activities)]\n",
    "filtered_collected_frames = collected_frames[feature_frames['activity'].isin(activities)]\n",
    "\n",
    "# Train the decision tree with the chosen classes\n",
    "# This function will print out precision/recall/accuracy\n",
    "dt_model, dt_cm, acc = train_decision_tree(filtered_feature_frames)\n",
    "\n",
    "# Save the classifier to disk. The name should be exactly dt_model.pkl\n",
    "with open(f'dt_model-{str(activities)}.pkl', 'wb') as f:\n",
    "    pickle.dump(dt_model, f)\n",
    "\n",
    "# Display the confusion matrix\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = dt_cm, display_labels=dt_model.classes_)\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "\n",
    "# Visualize the tree\n",
    "viz_tree(dt_model,feature_frames,feature_frames['activity'].unique().tolist())\n",
    "\n",
    "evaluate(dt_model, filtered_collected_frames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b68996",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = ['sitting','lying','standing']\n",
    "\n",
    "# Invert mask to keep only other rows\n",
    "filtered_feature_frames = feature_frames[feature_frames['activity'].isin(activities)]\n",
    "filtered_collected_frames = collected_frames[feature_frames['activity'].isin(activities)]\n",
    "\n",
    "# Train the decision tree with the chosen classes\n",
    "# This function will print out precision/recall/accuracy\n",
    "dt_model, dt_cm, acc = train_decision_tree(filtered_feature_frames)\n",
    "\n",
    "# Save the classifier to disk. The name should be exactly dt_model.pkl\n",
    "with open(f'dt_model-{str(activities)}.pkl', 'wb') as f:\n",
    "    pickle.dump(dt_model, f)\n",
    "\n",
    "# Display the confusion matrix\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = dt_cm, display_labels=dt_model.classes_)\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "\n",
    "# Visualize the tree\n",
    "viz_tree(dt_model,feature_frames,feature_frames['activity'].unique().tolist())\n",
    "\n",
    "evaluate(dt_model, filtered_collected_frames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969dd088",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = ['upstairs', 'walk_fast', 'walk_mod', 'walk_slow', 'downstairs', 'jogging']\n",
    "\n",
    "# Invert mask to keep only other rows\n",
    "filtered_feature_frames = feature_frames[feature_frames['activity'].isin(activities)]\n",
    "filtered_collected_frames = collected_frames[feature_frames['activity'].isin(activities)]\n",
    "\n",
    "# Train the decision tree with the chosen classes\n",
    "# This function will print out precision/recall/accuracy\n",
    "dt_model, dt_cm, acc = train_decision_tree(filtered_feature_frames)\n",
    "\n",
    "# Save the classifier to disk. The name should be exactly dt_model.pkl\n",
    "with open(f'dt_model-{str(activities)}.pkl', 'wb') as f:\n",
    "    pickle.dump(dt_model, f)\n",
    "\n",
    "# Display the confusion matrix\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = dt_cm, display_labels=dt_model.classes_)\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "\n",
    "# Visualize the tree\n",
    "viz_tree(dt_model,feature_frames,feature_frames['activity'].unique().tolist())\n",
    "evaluate(dt_model, filtered_collected_frames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987a4679",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = ['upstairs', 'walk_fast', 'walk_mod', 'walk_slow', 'downstairs', 'jogging', 'standing', 'lying', 'sitting']\n",
    "\n",
    "# Invert mask to keep only other rows\n",
    "filtered_feature_frames = feature_frames[feature_frames['activity'].isin(activities)]\n",
    "filtered_collected_frames = collected_frames[feature_frames['activity'].isin(activities)]\n",
    "\n",
    "# Train the decision tree with the chosen classes\n",
    "# This function will print out precision/recall/accuracy\n",
    "dt_model, dt_cm, acc = train_decision_tree(filtered_feature_frames)\n",
    "\n",
    "# Save the classifier to disk. The name should be exactly dt_model.pkl\n",
    "with open(f'dt_model-{str(activities)}.pkl', 'wb') as f:\n",
    "    pickle.dump(dt_model, f)\n",
    "\n",
    "# Display the confusion matrix\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = dt_cm, display_labels=dt_model.classes_)\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "\n",
    "# Visualize the tree\n",
    "viz_tree(dt_model,feature_frames,feature_frames['activity'].unique().tolist())\n",
    "evaluate(dt_model, filtered_collected_frames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3600d30c",
   "metadata": {},
   "source": [
    "**For the data in the dataset:**\n",
    "\n",
    "| Model trained on | Accuracy | Precision | Recall |\n",
    "|-|-|-|-|\n",
    "| Three Types of Walking | **FILL UP** |**FILL UP** |**FILL UP** |\n",
    "| Stairs Activities | **FILL UP** |**FILL UP** |**FILL UP** |\n",
    "| Static Activities | **FILL UP** |**FILL UP** |**FILL UP** |\n",
    "| Mobile Activities | **FILL UP** |**FILL UP** |**FILL UP** |\n",
    "| All Activities | **FILL UP** |**FILL UP** |**FILL UP** |\n",
    "|-|-|-|-|\n",
    "\n",
    "**For your own data:**\n",
    "| Model trained on | Accuracy | Precision | Recall |\n",
    "|-|-|-|-|\n",
    "| Three Types of Walking | **FILL UP** |**FILL UP** |**FILL UP** |\n",
    "| Stairs Activities | **FILL UP** |**FILL UP** |**FILL UP** |\n",
    "| Static Activities | **FILL UP** |**FILL UP** |**FILL UP** |\n",
    "| Mobile Activities | **FILL UP** |**FILL UP** |**FILL UP** |\n",
    "| All Activities | **FILL UP** |**FILL UP** |**FILL UP** |\n",
    "|-|-|-|-|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4018aaf1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 389.190769,
   "end_time": "2022-07-26T08:46:55.211994",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-26T08:40:26.021225",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
